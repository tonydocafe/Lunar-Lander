# ğŸš€ DQN Lunar Lander - Explorando o EspaÃ§o com InteligÃªncia Artificial! ğŸŒ•

Bem-vindo ao **DQN Lunar Lander**, um experimento onde ensinamos um agente a pousar suavemente em um planeta alienÃ­gena! ğŸŒŒğŸ›¸

---

## ğŸ¤– Sobre o Projeto

Neste projeto, utilizamos **Deep Q-Networks (DQN)** para treinar um agente no ambiente *LunarLander-v3*, fornecido pelo Gymnasium. O objetivo? Fazer com que nossa nave pouse de forma segura sem explodir! ğŸ’¥ğŸ”¥

---

## ğŸ“¦ Explicando o Script Linha por Linha

### 1ï¸âƒ£ ImportaÃ§Ã£o das Bibliotecas
```python
import gymnasium as gym
import numpy as np
from stable_baselines3 import DQN
from stable_baselines3.common.evaluation import evaluate_policy
```
**gymnasium**: Fornece o ambiente de simulaÃ§Ã£o.
**numpy**: Usado para operaÃ§Ãµes matemÃ¡ticas e manipulaÃ§Ã£o de arrays.
**DQN**: O algoritmo de aprendizado por reforÃ§o baseado em Q-Learning profundo.
**evaluate_policy**: FunÃ§Ã£o que avalia o desempenho do agente apÃ³s o treinamento.

### 2ï¸âƒ£ Criando o Ambiente
```python
env = gym.make("LunarLander-v3", render_mode="rgb_array")
```
**gym.make()** cria um ambiente de simulaÃ§Ã£o baseado no jogo Lunar Lander.
**render_mode="rgb_array"** configura a renderizaÃ§Ã£o para capturar imagens.

### 3ï¸âƒ£ DefiniÃ§Ã£o do Modelo DQN
```python
model = DQN(
    policy="MlpPolicy",
    env=env,
    verbose=1,
    learning_rate=1e-3,
    buffer_size=100_000,
    learning_starts=10_000,
    batch_size=64,
    gamma=0.99,
    exploration_fraction=0.1,
    exploration_final_eps=0.05,
    train_freq=4,
    target_update_interval=1000,
)
```
 **policy="MlpPolicy"**: PolÃ­tica de aprendizado baseada em redes neurais MLP (Multilayer Perceptron).
**env=env**: Associa o modelo ao ambiente.
**verbose=1**: InformaÃ§Ãµes sobre o treinamento.
**learning_rate=1e-3**: Taxa de aprendizado.
**buffer_size=100_000**: Tamanho do buffer de replay.
**learning_starts=10_000**: ComeÃ§a a aprender apÃ³s 10.000 interaÃ§Ãµes.
**batch_size=64**: Tamanho do lote para treinamento.
**gamma=0.99**: Fator de desconto para aprendizado futuro.
**exploration_fraction=0.1**: Fracionamento da exploraÃ§Ã£o durante o treinamento.
**exploration_final_eps=0.05**: Limite inferior da exploraÃ§Ã£o.
**train_freq=4**: FrequÃªncia de treinamento.
**target_update_interval=1000**: Intervalo para atualizar a rede-alvo.

### 4ï¸âƒ£ Treinamento do Modelo
```python
print("Iniciando treinamento...")
model.learn(total_timesteps=int(200_000), progress_bar=True)
```
**model.learn()**: Treina o agente por 200.000 timesteps.
**progress_bar=True**: Exibe o progresso do treinamento.

### 5ï¸âƒ£ Salvando o Modelo Treinado
```python
model.save("dqn_lunar")
print("Modelo salvo como dqn_lunar.zip")
```
- **model.save("dqn_lunar")**: Salva o modelo treinado em um arquivo ZIP.

### 6ï¸âƒ£ Recarregando o Modelo
```python
del model
model = DQN.load("dqn_lunar", env=env)
print("Modelo carregado!")
```
- **del model**: Remove o modelo da memÃ³ria.
- **DQN.load("dqn_lunar", env=env)**: Carrega o modelo salvo e associa ao ambiente.

### 7ï¸âƒ£ AvaliaÃ§Ã£o do Agente
```python
mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)
print(f"Recompensa mÃ©dia: {mean_reward:.2f} Â± {std_reward:.2f}")
```
- **evaluate_policy()**: Mede o desempenho do agente com 10 episÃ³dios de teste.
- **mean_reward**: MÃ©dia das recompensas obtidas.
- **std_reward**: Desvio padrÃ£o das recompensas.

### 8ï¸âƒ£ Executando o Agente Treinado
```python
obs, _ = env.reset()
rewards = []

for i in range(1000):
    action, _ = model.predict(obs, deterministic=True)
    obs, reward, done, _, _ = env.step(action)
    rewards.append(reward)
    env.render()
    
    if done:
        obs, _ = env.reset()
```
- **env.reset()**: Reinicia o ambiente.
- **model.predict(obs, deterministic=True)**: Escolhe a melhor aÃ§Ã£o baseada na polÃ­tica treinada.
- **env.step(action)**: Aplica a aÃ§Ã£o ao ambiente.
- **env.render()**: Renderiza a simulaÃ§Ã£o.
- **if done:** Reinicia o ambiente ao final do episÃ³dio.

### 9ï¸âƒ£ Fechando o Ambiente
```python
env.close()
```
- **env.close()**: Fecha a simulaÃ§Ã£o e libera os recursos.

---

## ğŸš€ Como Rodar o Projeto?

### 1ï¸âƒ£ Instale as dependÃªncias
```bash
pip install gymnasium numpy stable-baselines3
```

### 2ï¸âƒ£ Execute o script
```bash
python dqn_lunar.py
```

### 3ï¸âƒ£ Assista ao pouso (ou explosÃ£o)!
Se tudo der certo, seu agente pousarÃ¡ suavemente. Se nÃ£o... bem, foguetes sÃ£o difÃ­ceis de pilotar! ğŸ˜†

---

## ğŸ† ConclusÃ£o
Este README explica cada linha do script e como o Python interpreta os comandos. Agora, vocÃª pode entender e modificar o cÃ³digo para melhor desempenho ou criar novas versÃµes! ğŸš€ğŸ˜ƒ

Divirta-se e bons experimentos! ğŸ§ª

